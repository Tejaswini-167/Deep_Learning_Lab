{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvIOir__bunA"
      },
      "source": [
        "### Lab 13: DenseNet for Image Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFN3Mn-ObqjI",
        "outputId": "8ce6daea-a4d9-4779-e3ff-4662c7cce175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 3us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Resize images from 32x32 to 224x224 for DenseNet\n",
        "x_train_resized = tf.image.resize(x_train, (224, 224))\n",
        "x_test_resized = tf.image.resize(x_test, (224, 224))\n",
        "\n",
        "# Preprocess input for DenseNet\n",
        "x_train_prep = preprocess_input(x_train_resized)\n",
        "x_test_prep = preprocess_input(x_test_resized)\n",
        "\n",
        "# 2. Load DenseNet121 without top layers\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze convolutional base\n",
        "\n",
        "# 3. Build model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. Train model\n",
        "history = model.fit(\n",
        "    x_train_prep, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 5. Evaluate model\n",
        "test_loss, test_acc = model.evaluate(x_test_prep, y_test, verbose=0)\n",
        "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# 6. Plot training vs validation accuracy\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title(\"DenseNet121 Transfer Learning - Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 7. Plot training vs validation loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title(\"DenseNet121 Transfer Learning - Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 8. Sample predictions\n",
        "preds = model.predict(x_test_prep[:10])\n",
        "pred_labels = np.argmax(preds, axis=1)\n",
        "\n",
        "class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n",
        "               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title(f\"Pred: {class_names[pred_labels[i]]}\\nTrue: {class_names[int(y_test[i])]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# 9. Generate predictions for the entire test set\n",
        "y_pred_probs = model.predict(x_test_prep)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Flatten true labels\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "# 10. Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(\"Confusion Matrix - DenseNet121 CIFAR-10\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "# 11. Classification Report\n",
        "print(\"\\nClassification Report - DenseNet121 CIFAR-10\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
