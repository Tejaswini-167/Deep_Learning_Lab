## Lab 4: Loss Functions & Optimization Basics

### Objective
Explore foundational loss functions and optimizers used in neural network training.

### Key Concepts
- Purpose of a loss function in model learning
- Common loss types: Mean Squared Error (MSE) and Cross-Entropy
- Basic optimizers: Gradient Descent (GD), Stochastic GD (SGD), Adam

### Implementation
- Built a simple MLP for classification
- Trained using MSE and Cross-Entropy loss
- Applied different optimizers: GD, SGD, Adam
- Monitored training loss and accuracy

### Results / Observations
- Cross-Entropy outperformed MSE for classification
- Adam converged faster and more accurately than basic GD
